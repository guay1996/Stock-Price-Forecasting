{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>226.509995</td>\n",
       "      <td>228.869995</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>227.630005</td>\n",
       "      <td>227.630005</td>\n",
       "      <td>43340100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>228.410004</td>\n",
       "      <td>229.179993</td>\n",
       "      <td>226.630005</td>\n",
       "      <td>228.360001</td>\n",
       "      <td>228.360001</td>\n",
       "      <td>27390100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>228.990005</td>\n",
       "      <td>229.669998</td>\n",
       "      <td>225.100006</td>\n",
       "      <td>226.869995</td>\n",
       "      <td>226.869995</td>\n",
       "      <td>33333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>226.229996</td>\n",
       "      <td>227.350006</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>223.100006</td>\n",
       "      <td>223.100006</td>\n",
       "      <td>34290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>221.850006</td>\n",
       "      <td>225.369995</td>\n",
       "      <td>220.710007</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>37619800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>220.949997</td>\n",
       "      <td>221.850006</td>\n",
       "      <td>216.470001</td>\n",
       "      <td>218.330002</td>\n",
       "      <td>218.330002</td>\n",
       "      <td>39516500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>2018-09-11</td>\n",
       "      <td>218.009995</td>\n",
       "      <td>224.300003</td>\n",
       "      <td>216.559998</td>\n",
       "      <td>223.850006</td>\n",
       "      <td>223.850006</td>\n",
       "      <td>35749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>224.940002</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>219.839996</td>\n",
       "      <td>221.070007</td>\n",
       "      <td>221.070007</td>\n",
       "      <td>49278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4525</th>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>223.520004</td>\n",
       "      <td>228.350006</td>\n",
       "      <td>222.570007</td>\n",
       "      <td>226.410004</td>\n",
       "      <td>226.410004</td>\n",
       "      <td>41706400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4526</th>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>225.750000</td>\n",
       "      <td>226.839996</td>\n",
       "      <td>222.520004</td>\n",
       "      <td>223.839996</td>\n",
       "      <td>223.839996</td>\n",
       "      <td>31902700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "4517  2018-08-31  226.509995  228.869995  226.000000  227.630005  227.630005   \n",
       "4518  2018-09-04  228.410004  229.179993  226.630005  228.360001  228.360001   \n",
       "4519  2018-09-05  228.990005  229.669998  225.100006  226.869995  226.869995   \n",
       "4520  2018-09-06  226.229996  227.350006  221.300003  223.100006  223.100006   \n",
       "4521  2018-09-07  221.850006  225.369995  220.710007  221.300003  221.300003   \n",
       "4522  2018-09-10  220.949997  221.850006  216.470001  218.330002  218.330002   \n",
       "4523  2018-09-11  218.009995  224.300003  216.559998  223.850006  223.850006   \n",
       "4524  2018-09-12  224.940002  225.000000  219.839996  221.070007  221.070007   \n",
       "4525  2018-09-13  223.520004  228.350006  222.570007  226.410004  226.410004   \n",
       "4526  2018-09-14  225.750000  226.839996  222.520004  223.839996  223.839996   \n",
       "\n",
       "        Volume  \n",
       "4517  43340100  \n",
       "4518  27390100  \n",
       "4519  33333000  \n",
       "4520  34290000  \n",
       "4521  37619800  \n",
       "4522  39516500  \n",
       "4523  35749000  \n",
       "4524  49278700  \n",
       "4525  41706400  \n",
       "4526  31902700  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np \n",
    "import math\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "\n",
    "filename = 'Desktop\\AAPL (3).csv'\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "df.sort_values('Date')\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.13783425   4.263393     4.29380375 ... 222.71250125 225.21250525\n",
      " 224.737499  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Rong\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Yi Rong\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n",
      "C:\\Users\\Yi Rong\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Yi Rong\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "high_prices = df.loc[:,'High'].as_matrix()\n",
    "low_prices = df.loc[:,'Low'].as_matrix()\n",
    "open_prices = df.loc[:,'Open'].as_matrix()\n",
    "close_prices = df.loc[:,'Close'].as_matrix()\n",
    "OHLC_mean = (high_prices+low_prices+open_prices+close_prices)/4.0\n",
    "\n",
    "print(OHLC_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>OHLC Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4517</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>226.509995</td>\n",
       "      <td>228.869995</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>227.630005</td>\n",
       "      <td>227.630005</td>\n",
       "      <td>43340100</td>\n",
       "      <td>227.252499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4518</th>\n",
       "      <td>2018-09-04</td>\n",
       "      <td>228.410004</td>\n",
       "      <td>229.179993</td>\n",
       "      <td>226.630005</td>\n",
       "      <td>228.360001</td>\n",
       "      <td>228.360001</td>\n",
       "      <td>27390100</td>\n",
       "      <td>228.145001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>2018-09-05</td>\n",
       "      <td>228.990005</td>\n",
       "      <td>229.669998</td>\n",
       "      <td>225.100006</td>\n",
       "      <td>226.869995</td>\n",
       "      <td>226.869995</td>\n",
       "      <td>33333000</td>\n",
       "      <td>227.657501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>2018-09-06</td>\n",
       "      <td>226.229996</td>\n",
       "      <td>227.350006</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>223.100006</td>\n",
       "      <td>223.100006</td>\n",
       "      <td>34290000</td>\n",
       "      <td>224.495003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>221.850006</td>\n",
       "      <td>225.369995</td>\n",
       "      <td>220.710007</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>221.300003</td>\n",
       "      <td>37619800</td>\n",
       "      <td>222.307503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4522</th>\n",
       "      <td>2018-09-10</td>\n",
       "      <td>220.949997</td>\n",
       "      <td>221.850006</td>\n",
       "      <td>216.470001</td>\n",
       "      <td>218.330002</td>\n",
       "      <td>218.330002</td>\n",
       "      <td>39516500</td>\n",
       "      <td>219.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>2018-09-11</td>\n",
       "      <td>218.009995</td>\n",
       "      <td>224.300003</td>\n",
       "      <td>216.559998</td>\n",
       "      <td>223.850006</td>\n",
       "      <td>223.850006</td>\n",
       "      <td>35749000</td>\n",
       "      <td>220.680001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>224.940002</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>219.839996</td>\n",
       "      <td>221.070007</td>\n",
       "      <td>221.070007</td>\n",
       "      <td>49278700</td>\n",
       "      <td>222.712501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4525</th>\n",
       "      <td>2018-09-13</td>\n",
       "      <td>223.520004</td>\n",
       "      <td>228.350006</td>\n",
       "      <td>222.570007</td>\n",
       "      <td>226.410004</td>\n",
       "      <td>226.410004</td>\n",
       "      <td>41706400</td>\n",
       "      <td>225.212505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4526</th>\n",
       "      <td>2018-09-14</td>\n",
       "      <td>225.750000</td>\n",
       "      <td>226.839996</td>\n",
       "      <td>222.520004</td>\n",
       "      <td>223.839996</td>\n",
       "      <td>223.839996</td>\n",
       "      <td>31902700</td>\n",
       "      <td>224.737499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "4517  2018-08-31  226.509995  228.869995  226.000000  227.630005  227.630005   \n",
       "4518  2018-09-04  228.410004  229.179993  226.630005  228.360001  228.360001   \n",
       "4519  2018-09-05  228.990005  229.669998  225.100006  226.869995  226.869995   \n",
       "4520  2018-09-06  226.229996  227.350006  221.300003  223.100006  223.100006   \n",
       "4521  2018-09-07  221.850006  225.369995  220.710007  221.300003  221.300003   \n",
       "4522  2018-09-10  220.949997  221.850006  216.470001  218.330002  218.330002   \n",
       "4523  2018-09-11  218.009995  224.300003  216.559998  223.850006  223.850006   \n",
       "4524  2018-09-12  224.940002  225.000000  219.839996  221.070007  221.070007   \n",
       "4525  2018-09-13  223.520004  228.350006  222.570007  226.410004  226.410004   \n",
       "4526  2018-09-14  225.750000  226.839996  222.520004  223.839996  223.839996   \n",
       "\n",
       "        Volume   OHLC Mean  \n",
       "4517  43340100  227.252499  \n",
       "4518  27390100  228.145001  \n",
       "4519  33333000  227.657501  \n",
       "4520  34290000  224.495003  \n",
       "4521  37619800  222.307503  \n",
       "4522  39516500  219.400002  \n",
       "4523  35749000  220.680001  \n",
       "4524  49278700  222.712501  \n",
       "4525  41706400  225.212505  \n",
       "4526  31902700  224.737499  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OHLC Mean'] = OHLC_mean\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01410179]\n",
      " [0.01465439]\n",
      " [0.01478824]\n",
      " ...\n",
      " [0.97609053]\n",
      " [0.98709353]\n",
      " [0.98500294]]\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "OHLC_mean_scaled = OHLC_mean.reshape(-1,1)\n",
    "OHLC_mean_scaled = scaler.fit_transform(OHLC_mean_scaled)\n",
    "train_data = OHLC_mean_scaled[:4400]\n",
    "test_data = OHLC_mean_scaled[4400:]\n",
    "\n",
    "print(OHLC_mean_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4400, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import newaxis\n",
    "train_data = train_data.reshape(1,4400)\n",
    "train_data = train_data[:,:,newaxis]\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4399, 1)\n",
      "(1, 4399, 1)\n"
     ]
    }
   ],
   "source": [
    "trainX = train_data[:,:-1,:]\n",
    "trainY = train_data[:,1:,:]\n",
    "print (trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.0839\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0820\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0797\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0772\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0747\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0723\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0699\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0674\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.0648\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0622\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0595\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0567\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0538\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0508\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0477\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0445\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0412\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0378\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0343\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0308\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0273\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0238\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0202\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0168\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0135\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0105\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0079\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0059\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0047\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0044\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0046\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0043\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0033\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0021\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0015\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.0017\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0020\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0017\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 9.9712e-04\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 6.6682e-04\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.0012\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0014\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 8.9722e-04\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 7.0793e-04\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.0010\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.0012\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 9.1449e-04\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 5.9343e-04\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 5.9022e-04\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 7.3903e-04\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 6.4773e-04\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 13s 13s/step - loss: 4.1309e-04\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 3.5032e-04\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 4.6423e-04\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 5.2202e-04\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.3161e-04\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.4048e-04\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.8022e-04\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.6894e-04\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.5923e-04\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.7749e-04\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.4808e-04\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.8588e-04\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 4.0154e-04\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.5640e-04\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.0778e-04\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.0959e-04\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 3.3591e-04\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.3277e-04\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 3.0401e-04\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 13s 13s/step - loss: 2.9340e-04\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 3.1055e-04\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.2328e-04\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 3.1217e-04\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.9553e-04\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.9603e-04\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 3.0632e-04\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 13s 13s/step - loss: 3.0479e-04\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.9098e-04\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.8288e-04\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.8651e-04\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.8965e-04\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.8388e-04\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7663e-04\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.7719e-04\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.8206e-04\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.8213e-04\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7752e-04\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 11s 11s/step - loss: 2.7550e-04\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 12s 12s/step - loss: 2.7767e-04\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7854e-04\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7544e-04\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7230e-04\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.7241e-04\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.7337e-04\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.7190e-04\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.6929e-04\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.6852e-04\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.6919e-04\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 9s 9s/step - loss: 2.6880e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a500b90080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=16, batch_input_shape=(1,None,1),  stateful = True, return_sequences=True))\n",
    "model.add(LSTM(units=32, activation = 'relu', return_sequences = True))\n",
    "model.add(Dense(units =1))\n",
    "model.compile( loss='mean_squared_error', optimizer='adam')\n",
    "resetCallback = LambdaCallback(on_epoch_begin=lambda epoch,logs: model.reset_states())\n",
    "model.fit(trainX, trainY, batch_size=1, epochs=100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.78009546]]\n"
     ]
    }
   ],
   "source": [
    "#test_data = test_data.reshape(1, len(test_data),1)\n",
    "\n",
    "model.reset_states()\n",
    "trained_predictions = model.predict(train_data)\n",
    "#tested_predictions = model.predict(test_data) #provided test data is given, but unlikely to be the case\n",
    "\n",
    "print(trained_predictions[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.02881699]\n",
      "  [0.03100983]\n",
      "  [0.03284827]\n",
      "  ...\n",
      "  [0.77312225]\n",
      "  [0.7769122 ]\n",
      "  [0.78009546]]]\n",
      "[[[0.01410179]\n",
      "  [0.01465439]\n",
      "  [0.01478824]\n",
      "  ...\n",
      "  [0.79393626]\n",
      "  [0.78490283]\n",
      "  [0.78310934]]]\n"
     ]
    }
   ],
   "source": [
    "print(trained_predictions)\n",
    "print (train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.78009546]]]\n",
      "[array([[[0.78009546]]], dtype=float32), array([[[0.1345452]]], dtype=float32), array([[[0.12007935]]], dtype=float32), array([[[0.10616377]]], dtype=float32), array([[[0.09457921]]], dtype=float32), array([[[0.08503747]]], dtype=float32), array([[[0.07724612]]], dtype=float32), array([[[0.07074952]]], dtype=float32), array([[[0.06535493]]], dtype=float32), array([[[0.06056781]]], dtype=float32), array([[[0.056368]]], dtype=float32), array([[[0.052972]]], dtype=float32), array([[[0.05023013]]], dtype=float32), array([[[0.0480097]]], dtype=float32), array([[[0.04611928]]], dtype=float32), array([[[0.04459485]]], dtype=float32), array([[[0.04336893]]], dtype=float32), array([[[0.04238619]]], dtype=float32), array([[[0.04160119]]], dtype=float32), array([[[0.04097669]]], dtype=float32), array([[[0.04048215]]], dtype=float32), array([[[0.04009257]]], dtype=float32), array([[[0.03978746]]], dtype=float32), array([[[0.0395501]]], dtype=float32), array([[[0.03936685]]], dtype=float32), array([[[0.03922663]]], dtype=float32), array([[[0.03912044]]], dtype=float32), array([[[0.039041]]], dtype=float32), array([[[0.03898247]]], dtype=float32), array([[[0.03894014]]], dtype=float32), array([[[0.03891029]]], dtype=float32), array([[[0.03888994]]], dtype=float32), array([[[0.03887674]]], dtype=float32), array([[[0.03886885]]], dtype=float32), array([[[0.03886485]]], dtype=float32), array([[[0.03886363]]], dtype=float32), array([[[0.03886433]]], dtype=float32), array([[[0.03886632]]], dtype=float32), array([[[0.03886912]]], dtype=float32), array([[[0.03887238]]], dtype=float32), array([[[0.03887584]]], dtype=float32), array([[[0.03887931]]], dtype=float32), array([[[0.03888267]]], dtype=float32), array([[[0.03888585]]], dtype=float32), array([[[0.0388888]]], dtype=float32), array([[[0.03889149]]], dtype=float32), array([[[0.03889392]]], dtype=float32), array([[[0.03889607]]], dtype=float32), array([[[0.03889798]]], dtype=float32), array([[[0.03889965]]], dtype=float32), array([[[0.0389011]]], dtype=float32), array([[[0.03890235]]], dtype=float32), array([[[0.03890343]]], dtype=float32), array([[[0.03890435]]], dtype=float32), array([[[0.03890514]]], dtype=float32), array([[[0.0389058]]], dtype=float32), array([[[0.03890636]]], dtype=float32), array([[[0.03890683]]], dtype=float32), array([[[0.03890722]]], dtype=float32), array([[[0.03890754]]], dtype=float32), array([[[0.03890781]]], dtype=float32), array([[[0.03890804]]], dtype=float32), array([[[0.03890822]]], dtype=float32), array([[[0.03890837]]], dtype=float32), array([[[0.03890849]]], dtype=float32), array([[[0.03890859]]], dtype=float32), array([[[0.03890867]]], dtype=float32), array([[[0.03890873]]], dtype=float32), array([[[0.03890878]]], dtype=float32), array([[[0.03890882]]], dtype=float32), array([[[0.03890885]]], dtype=float32), array([[[0.03890888]]], dtype=float32), array([[[0.0389089]]], dtype=float32), array([[[0.03890891]]], dtype=float32), array([[[0.03890893]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890895]]], dtype=float32), array([[[0.03890895]]], dtype=float32), array([[[0.03890895]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890895]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32), array([[[0.03890894]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "predictions = model.predict(train_data)\n",
    "\n",
    "futureElements = []\n",
    "\n",
    "futureElement = predictions[:,-1:,:]\n",
    "futureElements.append(futureElement)\n",
    "print(futureElement)\n",
    "\n",
    "for i in range(120):\n",
    "    futureElement = model.predict(futureElement) #get the next step\n",
    "    futureElements.append(futureElement) #store the future steps    \n",
    "\n",
    "#after processing a sequence, reset the states for safety\n",
    "\n",
    "model.reset_states()\n",
    "print(futureElements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
